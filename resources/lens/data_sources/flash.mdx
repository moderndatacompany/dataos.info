---
title: "Flash"
description: "Flash is designed to optimize query performance by leveraging in-memory execution. When used with DataOS Lakehouse and Iceberg-format Depots, it enables efficient handling of large-scale queries by reducing latency and optimizing resource usage. The following explains how to configure Lens using Flash."
---

<Info>
  Flash is not classified as a DataOS source; instead, it serves query optimization to the Lens. However, it is included in the list of DataOS sources for user convenience and accessibility.
</Info>

### **Prerequisites**

To create a Lens using Flash, ensure that the Flash service is running and has a Persistent Volume attached. A Persistent Volume allows Flash to spill data to disk, enhancing performance by preventing memory constraints from impacting query execution.

<Info>
  Make sure a Persistent Volume is attached with the Flash. It helps Flash to spill data over disk, which helps with the performance.
</Info>

<Steps>
  <Step title="Create Persistent Volume manifest file" titleSize="h2">
    To create a Persistence Volume manifest file copy  the template below and replace with your desired resource name and with the appropriate volume size (e.g., `100Gi`, `20Gi`, etc.), according to your available storage capacity. For the accessMode, you can choose ReadWriteOnce (RWO) for exclusive read-write access by a single node, or ReadOnlyMany (ROX) if the volume needs to be mounted as read-only by multiple nodes.

    ```yaml
    name: <name>  # Name of the Resource
    version: v1beta  # Manifest version of the Resource
    type: volume  # Type of Resource
    tags:  # Tags for categorizing the Resource
      - volume
    description: Common attributes applicable to all DataOS Resources
    layer: user
    volume:
      size: <size>  # Example: 100Gi, 50Mi, 10Ti, 500Mi, 20Gi
      accessMode: <accessMode>  # Example: ReadWriteOnce, ReadOnlyMany
      type: temp
    ```

    <Note>
      The persistent volume size should be at least 2.5 times the total dataset size, rounded to the nearest multiple of 10. To check the dataset size, use the following query:

      `SELECT sum(total_size) FROM "<catalog>"."<schema>"."<table>$partitions";`

      The resultant size will be in the bytes.
    </Note>
  </Step>

  <Step title="Apply the Volume manifest file" titleSize="h2">
    Deploy the persistent volume using the following `apply` command in terminal:

    ```bash
    dataos-ctl apply -f <file path of persistent volume>

    ```

    [](https://dataos.info/resources/lens/data_sources/flash/#__codelineno-2-1)

    Once deployed the Persistent Volume will be available for use by Flash Service.
  </Step>

  <Step title="Create Service manifest file" titleSize="h2">
    Ensure the name of the Persistent Volume you created is referenced correctly in the name attribute of the persistentVolume section. The name used here should match exactly with the name you assigned to the Persistent Volume during its creation.

    ```yaml
    name: flash-service-lens
    version: v1
    type: service
    tags:
      - service
    description: flash service
    workspace: curriculum
    service:
      servicePort: 5433
      replicas: 1
      logLevel: info

      compute: runnable-default

      resources:
        requests:
          cpu: 1000m
          memory: 1024Mi

      persistentVolume:
        name: <persistent_volume_name>
        directory: p_volume

      stack: flash+python:2.0

      stackSpec:
        datasets:
          - address: dataos://onelakehouse:sales360/f_sales    #view
            name: sales

          - address: dataos://onelakehouse:sales360/customer_data_master
            name: customer_data_master

          - address: dataos://onelakehouse:sales360/site_check1
            name: site_check1

          - address: dataos://onelakehouse:sales360/product_data_master
            name: product_data_master

        init:
          - create table if not exists f_sales as (select * from sales)  #table
          - create table if not exists m_customers as (select * from customer_data_master)
          - create table if not exists m_sites as (select * from site_check1)
          - create table if not exists table m_products as (select * from product_data_master)
    ```

    ### **How does this process work?**

    The flow of Flash operates as follows:

    * **Data loading:** The `datasets` attribute specifies the depot `address` of the source data to be loaded into Flash. A dataset `name` is  provided, which Flash uses to generate a view of the source data.

    * **View creation:** Flash creates a view based on the assigned name, allowing for interaction with the source data without directly querying it.

    * **Table creation:** The `init` attribute allows specific columns from the generated view to be selected and defined as tables. These tables are available for use in SQL queries within Lens. Tables are created only **if they don’t already exist**, using the `IF NOT EXISTS` clause. If tables are already present, the process **skips creation** and proceeds with the existing schema.

    * **Usage in Lens model(SQL):**  For example, in the manifest referenced, the `f_sales` table is first loaded from the source, and a view named `sales` is created. A table called `f_sales` is then defined using this sales view. This table is then referenced in SQL models within Lens.
  </Step>

  <Step title="Apply the Flash manifest file" titleSize="h2">
    Deploy the Flash Service, using the following `apply` command:

    ```yaml
    dataos-ctl apply -f <file path of flash service>
    ```

    This will deploy the  Flash Service ready to be used as source in Lens.
  </Step>
</Steps>

## Step 2 Prepare the semantic model folder

In the Model folder, the semantic model will be defined, encompassing SQL mappings, logical tables, logical views, and user groups. Each subfolder contains specific files related to the Lens model. You can download the Lens template to quickly get started.

[lens template](/resources/lens/lens_model_folder_setup/lens-project-template.zip)

<Steps>
  <Step title="Load data from the data source" titleSize="h2">
    In the `sqls` folder, create `.sql` files for each logical table, where each file is responsible for loading or selecting the relevant data from the source. Ensure that only the necessary columns are extracted, and the SQL dialect is specific to the data source. For Flash, the table name given in the  `init` will be the source table name.

    For example, a simple data load might look as follows:

    ```sql
    SELECT
      *
    FROM
      channel; # flash source table name
    ```

    Alternatively, you can write more advanced queries that include transformations, such as:

    ```sql
    SELECT
      CAST(customer_id AS VARCHAR) AS customer_id,
      first_name,
      CAST(DATE_PARSE(birth_date, '%d-%m-%Y') AS TIMESTAMP) AS birth_date,
      age,
      CAST(register_date AS TIMESTAMP) AS register_date,
      occupation,
      annual_income,
      city,
      state,
      country,
      zip_code
    FROM
      customer;
    ```
  </Step>

  <Step title="Define the table in the Model" titleSize="h2">
    Create a `tables` folder to store logical table definitions, with each table defined in a separate YAML file outlining its dimensions, measures, and segments. For example, to define a table for `sales `data:

    ```yaml
    table:
      - name: customers
        sql: {{ load_sql('customers') }}
        description: Table containing information about sales transactions.
    ```

    ### Add dimensions and measures

    After defining the base table, add the necessary dimensions and measures. For example, to create a table for sales data with measures and dimensions, the YAML definition could look as follows:

    ```yaml
    tables:
      - name: sales
        sql: {{ load_sql('sales') }}
        description: Table containing sales records with order details.

        dimensions:
          - name: order_id
            type: number
            description: Unique identifier for each order.
            sql: order_id
            primary_key: true
            public: true

        measures:
          - name: total_orders_count
            type: count
            sql: id
            description: Total number of orders.
    ```

    ### Add segments to filter

    Segments are filters that allow for the application of specific conditions to refine the data analysis. By defining segments, you can focus on particular subsets of data, ensuring that only the relevant records are included in your analysis. For example, to filter for records where the state is either Illinois or Ohio, you can define a segment as follows:

    ```yaml
    segments:
      - name: state_filter
        sql: "{TABLE}.state IN ('Illinois', 'Ohio')"
    ```

    To know more about segments click [here](https://dataos.info/resources/lens/working_with_segments/).
  </Step>

  <Step title="Create the views" titleSize="h2">
    Create a **views** folder to store all logical views, with each view defined in a separate YAML file (e.g., `sample_view.yml`). Each view references dimensions, measures, and segments from multiple logical tables. For instance the following`customer_churn` view is created.

    ```yaml
    views:
      - name: customer_churn_prediction
        description: Contains customer churn information.
        tables:
          - join_path: marketing_campaign
            includes:
              - engagement_score
              - customer_id
          - join_path: customer
            includes:
              - country
              - customer_segments
    ```

    To know more about the views click [here](https://dataos.info/resources/lens/working_with_views/).
  </Step>

  <Step title="Create user groups" titleSize="h2">
    The `user_groups.yml` manifest file is used to manage access levels for the semantic model. It defines user groups that organize users based on their access privileges. In this file, you can create multiple groups and assign different users to each group, allowing you to control access to the model.By default, the 'default' user group in the manifest file includes all users.

    ```yaml
    user_groups:
      - name: default
        description: this is a default user group
        includes: "*"
    ```

    You can create multiple user groups in `user_groups.yml` . To know more about the User groups click [here](https://dataos.info/resources/lens/working_with_user_groups_and_data_policies/).
  </Step>
</Steps>

## Step 3 Create Instance-secret&#x20;

Before creating the `lens_deployment.yml` file, ensure that an **Instance Secret** is deployed with the credentials required to access a hosted code repository, such as [Bitbucket](https://support.atlassian.com/bitbucket-cloud/docs/push-code-to-bitbucket/), [GitHub](https://docs.github.com/en/migrations/importing-source-code/using-the-command-line-to-import-source-code/adding-locally-hosted-code-to-github), [AWS CodeCommit](https://docs.aws.amazon.com/codecommit/latest/userguide/getting-started.html) etc. The `lens_deployment.yml` configuration relies on this repository to fetch the **semantic model**, making the Instance Secret a critical prerequisite for deployment. 

<Note>
  If your code repository is private, you will need to create **Instance Secrets** with your repository credentials for later use during deployment. Public code repositories do not require Step 3.
</Note>

Define the Instance Secret Resource in a  YAML manifest file. Below is a template you can use for Bitbucket, substituting `${USERNAME}` and `${PASSWORD}` with your actual Bitbucket credentials:

<CodeGroup>
  ```yaml Syntax
  # RESOURCE META SECTION
  name: ${bitbucket-r } # Secret Resource name (mandatory)
  version: v1 # Secret manifest version (mandatory)
  type: instance-secret # Type of Resource (mandatory)
  description: Bitbucket read secrets for code repository # Secret Resource description (optional)
  layer: user # DataOS Layer (optional)

  # INSTANCE SECRET-SPECIFIC SECTION
  instance-secret: 
    type: key-value # Type of Instance-secret (mandatory)
    acl: r # Access control list (mandatory)
    data: # Data (mandatory)
      GITSYNC_USERNAME: ${USERNAME}
      GITSYNC_PASSWORD: ${PASSWORD}
  ```

  ```yaml Example
  # RESOURCE META SECTION
  name: bitbucket-r # Secret Resource name (mandatory)
  version: v1 # Secret manifest version (mandatory)
  type: instance-secret # Type of Resource (mandatory)
  description: Bitbucket read secrets for code repository # Secret Resource description (optional)
  layer: user # DataOS Layer (optional)

  # INSTANCE SECRET-SPECIFIC SECTION
  instance-secret: 
    type: key-value # Type of Instance-secret (mandatory)
    acl: r # Access control list (mandatory)
    data: # Data (mandatory)
      GITSYNC_USERNAME: iamgroot
      GITSYNC_PASSWORD: <git_token>
  ```
</CodeGroup>

### **Apply the Instance Secret manifest**

Deploy the Instance Secret to DataOS using the `apply` command.

```
dataos-ctl apply -f {manifest-file-path}
```

<Warning>
  When applying the manifest file for Instance-secret from CLI, make sure you don't specify Workspace as Instance Secrets are [Instance-level Resource](/resources/types/#instance-level-resources).
</Warning>

## Step 4 Create Lens Resource

To enable Lens to interact with the Flash service, configure the following attributes in the Lens deployment manifest file:

### **1. Define Flash as the data source**

Configure the Flash service as the data source in the `source` attribute of the deployment manifest file.

**`source`**

* **`type`** The source section specifies that Flash is used as the data source (`type: flash`). This indicates that data for the Lens model will be loaded from the Flash service.

* **`name`**: The Flash service is identified by the `name` attribute, here it is flash-service-lens. This name should match the deployed Flash service used for data ingestion. Below is an example configuration.

```yaml
source:
  type: flash  # Specifies the data source type as Flash
  name: flash-test  # Name of the Flash service
```

### **2. Add environment variables**

Specify the following environment variables in the Worker, API, and Router sections of the Lens deployment manifest.

**`envs`**

The following environment variables are defined under multiple components, including api, worker, router, and iris

* **`LENS2_SOURCE_WORKSPACE_NAME`** It refers to the workspace where the Flash service is deployed.

* **`LENS2_SOURCE_FLASH_PORT`** The port number `5433` is specified for the Flash service. This port is used by Lens to establish communication with the Flash service. It ensures that all components—API, worker, router, and iris—can access the Flash service consistently.

```yaml
envs:
  LENS2_SOURCE_WORKSPACE_NAME: public
  LENS2_SOURCE_FLASH_PORT: 5433
```

After configuring with above attributes, the Lens deployment manifest file will be as follows:

```yaml
version: v1alpha
name: "lens-flash-test-99"
layer: user
type: lens
tags:
  - lens
description: A sample lens that contains three entities, a view and a few measures for users to test
lens:
  compute: runnable-default
  secrets: # Referred Instance-secret configuration (**mandatory for private code repository, not required for public repository)
    - name: githubr # Referred Instance Secret name (mandatory)
      allKeys: true # All keys within the secret are required or not (optional)
  source:
    type: flash # minerva, themis and depot
    name: flash-service-lens # flash service name
  repo:
    url: https://github.com/tmdc/sample    # repo address
    lensBaseDir: sample/source/flash/model     # location where lens models are kept in the repo
    syncFlags:
      - --ref=main
  api:
    replicas: 1
    logLevel: debug
    envs:
      LENS2_SOURCE_WORKSPACE_NAME: curriculum
      LENS2_SOURCE_FLASH_PORT: 5433
    resources: # optional
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 2000m
        memory: 2048Mi

  worker:
    replicas: 1
    logLevel: debug
    envs:
      LENS2_SOURCE_WORKSPACE_NAME: curriculum
      LENS2_SOURCE_FLASH_PORT: 5433
    resources: # optional
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 6000m
        memory: 6048Mi

  router:
    logLevel: info
    envs:
      LENS2_SOURCE_WORKSPACE_NAME: curriculum
      LENS2_SOURCE_FLASH_PORT: 5433
    resources: # optional
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 6000m
        memory: 6048Mi

  iris:
    logLevel: info  
    envs:
      LENS2_SOURCE_WORKSPACE_NAME: curriculum
      LENS2_SOURCE_FLASH_PORT: 5433
    resources: # optional
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 6000m
        memory: 6048Mi
```

### Apply the Lens manifest file

Deploy the Lens by using the following `apply` command:

```
dataos-ctl apply -f {manifest-file-path}
```