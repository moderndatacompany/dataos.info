---
title: "Scanner for BigQuery"
---

For the BigQuery data Warehouse the prerequisites and manifest configurations for extracting entity metadata are:

## **Requirements**

To scan the metadata from BigQuery, User need the following:

* Ensure that the BigQuery project is created.

* BigQuery user must have`viewer`¬†privilege on the warehouse.

* User should have enough access to fetch the required metadata. The following list describes the minimum required permissions.

* **Access Permission to Run a Scanner Workflow**&#x20;
  Verify that the use case or role tag for executing a Scanner Workflow is approved, which are as follows:| Access using Role Tag | Access using Use cases         |
  | --------------------- | ------------------------------ |
  | `roles:id:data-dev`   | Read Workspace                 |
  | `roles:id:system-dev` | Run as Scanner User            |
  | `roles:id:user`       | Manage All Depot               |
  |                       | Read All Dataset               |
  |                       | Read all secrets from Heimdall |

* Pre-created AzureSQL Depot
  Ensure that a AzureSQL Depot is already created with valid read access and the necessary permissions to extract metadata. To check the Depot go to the Metis UI of the DataOS or use the following command:

```bash
dataos-ctl get -t depot -a

#expected output

INFO[0000] üîç get...                                     
INFO[0000] üîç get...complete                             

            NAME            | VERSION | TYPE  | WORKSPACE | STATUS |   RUNTIME   |         OWNER          
----------------------------|---------|-------|-----------|--------|-------------|------------------------
  mongodepot                | v2alpha | depot |           | active |             | Jhon Doe
  snowflakedepot            | v2alpha | depot |           | active |             | JOJO
  redshiftdepot             | v2alpha | depot |           | active |             | Kira
  mysqldepot                | v2alpha | depot |           | active |             | Ryuk
  oracle01                  | v2alpha | depot |           | active |             | drdoom
  mariadb01                 | v2alpha | depot |           | active |             | tonystark
  demopreppostgres          | v2alpha | depot |           | active |             | slimshaddy
	demoprepbq                | v2alpha | depot |           | active |             | pengvin
  mssql01                   | v2alpha | depot |           | active |             | hulk
  kafka01                   | v2alpha | depot |           | active |             | peeter
  icebase                   | v2alpha | depot |           | active |             | blackpink
  azuresql                  | v2alpha | depot |           | active |             | arnold
  fastbase                  | v2alpha | depot |           | active |             | ddevil
```

Template for creating BIGQUERY Depot is shown below:

```yaml
name: ${{depot-name}}
version: v2alpha
type: depot
tags:
  - ${{dropzone}}
  - ${{bigquery}}
owner: ${{owner-name}}
layer: user
depot:
  type: BIGQUERY                 
  description: ${{description}} # optional
  external: ${{true}}
  secrets:
    - name: ${{bq-instance-secret-name}}-r
      allkeys: true

    - name: ${{bq-instance-secret-name}}-rw
      allkeys: true
  bigquery:  # optional                         
    project: ${{project-name}} # optional
    params: # optional
      ${{"key1": "value1"}}
      ${{"key2": "value2"}}
```

## **Scanner Workflow**

DataOS enables the creation of a Depot of type 'BIGQUERY' for accessing data stored in BigQuery projects. Multiple Depots can be established, each directed towards a different project. The following manifest scans metadata from a BigQuery-type Depot.

<Info>
  Ensure that the Depot is created and you have `read` access for the depot.
</Info>

```yaml

version: v1
name: wf-bigquery-depot
type: workflow
tags:
  - bigquery-depot
description: The workflow scans schema tables and register data
workflow:
  dag:
    - name: bigquery-depot
      description: The job scans schema from bigquery-depot tables and register data to metis2
      spec:
        tags:
          - scanner
        stack: scanner:2.0
        compute: runnable-default
        runAsUser: metis
        stackSpec:
          depot: demoprepbq           
          sourceConfig:           
            config:
              markDeletedTables: false
              includeTables: true
              includeViews: true
              databaseFilterPattern:
                includes:
                  - <databasename> 
                excludes:
                  - <databasename> 
              schemaFilterPattern:
                includes:
                  - <schemaname>
                excludes:
                  - <schemaname>
              tableFilterPattern:
                includes:
                  - <schemaname>
                excludes:
                  - <schemaname>

```

The above sample manifest file is deployed using the following command:

```
dataos-ctl resource apply -f {path to the Scanner YAML}
```

<Note>
  If the Depot or Scanner configurations are updated, the Scanner must be redeployed after deleting the previous instance. Use the following command to delete the existing Scanner:

  ```
  dataos-ctl resource delete -f {path to the Scanner YAML file}
  ```
</Note>