<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyflare.sdk.core.session_builder &mdash; Dataos Pyflare 0.1.13 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            Dataos Pyflare
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../pyflare.sdk.html">pyflare.sdk package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Dataos Pyflare</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pyflare.sdk.core.session_builder</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyflare.sdk.core.session_builder</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">Logger</span>

<span class="kn">from</span> <span class="nn">pyspark.conf</span> <span class="kn">import</span> <span class="n">SparkConf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="kn">from</span> <span class="nn">pyflare.sdk.config.constants</span> <span class="kn">import</span> <span class="n">INPUT_STRING</span><span class="p">,</span> <span class="n">OUTPUT_STRING</span><span class="p">,</span> <span class="n">SPARK_APP_NAME</span><span class="p">,</span> <span class="n">get_spark_app_name</span><span class="p">,</span> \
    <span class="n">get_log4j_properties_path</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.utils</span> <span class="kn">import</span> <span class="n">pyflare_logger</span><span class="p">,</span> <span class="n">generic_utils</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.config</span> <span class="kn">import</span> <span class="n">constants</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.config.read_config</span> <span class="kn">import</span> <span class="n">ReadConfig</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.config.write_config</span> <span class="kn">import</span> <span class="n">WriteConfig</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.depots</span> <span class="kn">import</span> <span class="n">client</span>

<span class="c1"># DO NOT REMOVE IMPORTS, readers used at runtime</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.reader</span> <span class="kn">import</span> <span class="n">Reader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.file_reader</span> <span class="kn">import</span> <span class="n">FileInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.iceberg_reader</span> <span class="kn">import</span> <span class="n">IcebergInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.jdbc_reader</span> <span class="kn">import</span> <span class="n">JDBCInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.delta_reader</span> <span class="kn">import</span> <span class="n">DeltaInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.fastbase_reader</span> <span class="kn">import</span> <span class="n">FastBaseInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.snowflake_reader</span> <span class="kn">import</span> <span class="n">SnowflakeInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.bigquery_reader</span> <span class="kn">import</span> <span class="n">BigqueryInputReader</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.readers.elasticsearch_reader</span> <span class="kn">import</span> <span class="n">ElasticSearchInputReader</span>

<span class="c1"># DO NOT REMOVE IMPORTS, writers used at runtime</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.utils.generic_utils</span> <span class="kn">import</span> <span class="n">resolve_dataos_address</span><span class="p">,</span> <span class="n">get_env_variable</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.utils.pyflare_exceptions</span> <span class="kn">import</span> <span class="n">InvalidInputException</span><span class="p">,</span> <span class="n">PyflareReadException</span><span class="p">,</span> <span class="n">PyflareWriteException</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.utils.pyflare_logger</span> <span class="kn">import</span> <span class="n">create_log4j_on_disk</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.writer</span> <span class="kn">import</span> <span class="n">Writer</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.file_writer</span> <span class="kn">import</span> <span class="n">FileOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.iceberg_writer</span> <span class="kn">import</span> <span class="n">IcebergOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.jdbc_writer</span> <span class="kn">import</span> <span class="n">JDBCOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.delta_writer</span> <span class="kn">import</span> <span class="n">DeltaOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.fastbase_writer</span> <span class="kn">import</span> <span class="n">FastBaseOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.snowflake_writer</span> <span class="kn">import</span> <span class="n">SnowflakeOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.bigquery_writer</span> <span class="kn">import</span> <span class="n">BigqueryOutputWriter</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.writers.elasticsearch_writer</span> <span class="kn">import</span> <span class="n">ElasticSearchOutputWriter</span>

<span class="kn">from</span> <span class="nn">pyflare.sdk.core.dataos_input</span> <span class="kn">import</span> <span class="n">DataOSInput</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.core.minerva_input</span> <span class="kn">import</span> <span class="n">MinervaInput</span>
<span class="kn">from</span> <span class="nn">pyflare.sdk.core.dataos_output</span> <span class="kn">import</span> <span class="n">DataOSOutput</span>

<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>
<span class="kn">from</span> <span class="nn">py4j.java_gateway</span> <span class="kn">import</span> <span class="n">java_import</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span>

<span class="n">spark</span><span class="p">:</span> <span class="n">SparkSession</span>
<span class="n">g_inputs</span><span class="p">:</span> <span class="nb">dict</span>
<span class="n">g_outputs</span><span class="p">:</span> <span class="nb">dict</span>
<span class="n">g_dataos_token</span><span class="p">:</span> <span class="nb">str</span>


<div class="viewcode-block" id="SparkSessionBuilder"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder">[docs]</a><span class="k">class</span> <span class="nc">SparkSessionBuilder</span><span class="p">:</span>
    <span class="n">spark</span><span class="p">:</span> <span class="n">SparkSession</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">spark_conf</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">parsed_inputs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">parsed_outputs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">api_token</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">dataos_fqdn</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">log_level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;INFO&quot;</span>
    <span class="n">logger</span><span class="p">:</span> <span class="n">Logger</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_level</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_level</span> <span class="o">=</span> <span class="n">log_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">pyflare_logger</span><span class="o">.</span><span class="n">setup_pyflare_logger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="n">create_log4j_on_disk</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>

<div class="viewcode-block" id="SparkSessionBuilder.build_session"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.build_session">[docs]</a>    <span class="k">def</span> <span class="nf">build_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSession</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spark</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_default_spark_conf</span><span class="p">()</span>
            <span class="n">conf_obj</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span><span class="n">setAll</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="p">))</span>
            <span class="n">spark_builder</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf_obj</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spark</span> <span class="o">=</span> <span class="n">spark_builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
        <span class="n">refresh_global_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">spark</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.load_default_spark_conf"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.load_default_spark_conf">[docs]</a>    <span class="k">def</span> <span class="nf">load_default_spark_conf</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSessionBuilder</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>
                               <span class="p">(</span><span class="s2">&quot;spark.app.name&quot;</span><span class="p">,</span> <span class="n">get_spark_app_name</span><span class="p">()))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;spark.redaction.regex&quot;</span><span class="p">,</span> <span class="s2">&quot;(?i)secret|password|key|abfss|dfs|apikey&quot;</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;spark.driverEnv.DATAOS_RUN_AS_APIKEY&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;spark.heimdall.udf.provider&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;io.dataos.flare.authz.DataOSSparkUdfProvider&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;spark.sql.extensions&quot;</span><span class="p">,</span> <span class="s2">&quot;org.apache.iceberg.spark.extensions&quot;</span>
                                                           <span class="s2">&quot;.IcebergSparkSessionExtensions&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;spark.driver.extraJavaOptions&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;-Dlog4j.configuration=file:</span><span class="si">{</span><span class="n">get_log4j_properties_path</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;spark.executor.extraJavaOptions&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;-Dlog4j.configuration=file:</span><span class="si">{</span><span class="n">get_log4j_properties_path</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_spark_conf"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_spark_conf">[docs]</a>    <span class="k">def</span> <span class="nf">with_spark_conf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSessionBuilder</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span> <span class="o">+=</span> <span class="n">conf</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;spark.app.name&quot;</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">SPARK_APP_NAME</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span> <span class="k">if</span> <span class="n">value</span> <span class="k">else</span> <span class="n">constants</span><span class="o">.</span><span class="n">SPARK_APP_NAME_PREFIX</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_readers"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_readers">[docs]</a>    <span class="k">def</span> <span class="nf">with_readers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reader_address_list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSessionBuilder</span><span class="p">:</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_writers"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_writers">[docs]</a>    <span class="k">def</span> <span class="nf">with_writers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer_address_list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSessionBuilder</span><span class="p">:</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_depot"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_depot">[docs]</a>    <span class="k">def</span> <span class="nf">with_depot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depot_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">acl</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SparkSessionBuilder</span><span class="p">:</span>
        <span class="c1">###</span>
        <span class="c1"># This code will be used if we support multi format read from same depot.</span>
        <span class="c1"># This has footprint in other classes, just blocking the entry point.</span>
        <span class="c1">###</span>
        <span class="c1"># if format_list is None:</span>
        <span class="c1">#     format_list = [&quot;&quot;]</span>
        <span class="c1"># if type(format_list) is not list:</span>
        <span class="c1">#     raise InvalidInputException(&quot;format_list cannot be empty, define list of formats to be used with_depot()&quot;)</span>
        <span class="n">format_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;rw&quot;</span> <span class="o">==</span> <span class="n">acl</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_reader_instance</span><span class="p">(</span><span class="n">depot_name</span><span class="p">,</span> <span class="n">format_list</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_writer_instance</span><span class="p">(</span><span class="n">depot_name</span><span class="p">,</span> <span class="n">format_list</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;r&quot;</span> <span class="o">==</span> <span class="n">acl</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_reader_instance</span><span class="p">(</span><span class="n">depot_name</span><span class="p">,</span> <span class="n">format_list</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InvalidInputException</span><span class="p">(</span><span class="s2">&quot;invalid value of acl, please assign an acceptable value [&#39;r&#39;, &#39;rw&#39;]&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.add_writer_instance"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.add_writer_instance">[docs]</a>    <span class="k">def</span> <span class="nf">add_writer_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depot_name</span><span class="p">,</span> <span class="n">format_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">curr_format</span> <span class="ow">in</span> <span class="n">format_list</span><span class="p">:</span>
            <span class="n">writer_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_write_instance</span><span class="p">(</span><span class="n">depot_name</span><span class="o">=</span><span class="n">depot_name</span><span class="p">,</span> <span class="n">write_format</span><span class="o">=</span><span class="n">curr_format</span><span class="p">)</span>
            <span class="n">curr_format</span> <span class="o">=</span> <span class="n">writer_instance</span><span class="o">.</span><span class="n">write_config</span><span class="o">.</span><span class="n">io_format</span>
            <span class="c1"># writer_instance._view_name = f&quot;{depot_name}_{curr_format}&quot;  # to be used in case of multi format use case</span>
            <span class="n">writer_instance</span><span class="o">.</span><span class="n">_view_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">depot_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parsed_outputs</span><span class="p">[</span><span class="n">writer_instance</span><span class="o">.</span><span class="n">_view_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;writer_instance&quot;</span><span class="p">:</span> <span class="n">writer_instance</span><span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span> <span class="o">+=</span> <span class="n">writer_instance</span><span class="o">.</span><span class="n">get_conf</span><span class="p">()</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.add_reader_instance"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.add_reader_instance">[docs]</a>    <span class="k">def</span> <span class="nf">add_reader_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depot_name</span><span class="p">,</span> <span class="n">format_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">curr_format</span> <span class="ow">in</span> <span class="n">format_list</span><span class="p">:</span>
            <span class="n">reader_instance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_read_instance</span><span class="p">(</span><span class="n">depot_name</span><span class="o">=</span><span class="n">depot_name</span><span class="p">,</span> <span class="n">read_format</span><span class="o">=</span><span class="n">curr_format</span><span class="p">)</span>
            <span class="n">curr_format</span> <span class="o">=</span> <span class="n">reader_instance</span><span class="o">.</span><span class="n">read_config</span><span class="o">.</span><span class="n">io_format</span>
            <span class="c1"># reader_instance._view_name = f&quot;{depot_name}_{curr_format}&quot;  # to be used in case of multi format use case</span>
            <span class="n">reader_instance</span><span class="o">.</span><span class="n">_view_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">depot_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parsed_inputs</span><span class="p">[</span><span class="n">reader_instance</span><span class="o">.</span><span class="n">_view_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;reader_instance&quot;</span><span class="p">:</span> <span class="n">reader_instance</span><span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spark_conf</span> <span class="o">+=</span> <span class="n">reader_instance</span><span class="o">.</span><span class="n">get_conf</span><span class="p">()</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_user_apikey"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_user_apikey">[docs]</a>    <span class="k">def</span> <span class="nf">with_user_apikey</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">apikey</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_token</span> <span class="o">=</span> <span class="n">apikey</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SparkSessionBuilder.with_dataos_fqdn"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.SparkSessionBuilder.with_dataos_fqdn">[docs]</a>    <span class="k">def</span> <span class="nf">with_dataos_fqdn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataos_fqdn</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataos_fqdn</span> <span class="o">=</span> <span class="n">dataos_fqdn</span>
        <span class="n">constants</span><span class="o">.</span><span class="n">DATAOS_BASE_URL</span> <span class="o">=</span> <span class="n">dataos_fqdn</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">__get_read_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depot_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">read_format</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Reader</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_local</span><span class="p">(</span><span class="n">depot_name</span><span class="p">):</span>
            <span class="n">depot_details</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;connection&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;localUrl&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">depot_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">depot_details</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">DepotClientAPI</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">)</span><span class="o">.</span><span class="n">get_depot_details</span><span class="p">(</span><span class="n">depot_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">read_format</span><span class="p">:</span>
            <span class="n">depot_details</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_format</span>
        <span class="n">conf_obj</span> <span class="o">=</span> <span class="n">ReadConfig</span><span class="p">(</span><span class="n">depot_details</span><span class="o">=</span><span class="n">depot_details</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__create_input_instance</span><span class="p">(</span><span class="s2">&quot;Reader&quot;</span><span class="p">,</span> <span class="n">conf_obj</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__get_write_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depot_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">write_format</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Writer</span><span class="p">:</span>
        <span class="n">depot_details</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">DepotClientAPI</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">api_token</span><span class="p">)</span><span class="o">.</span><span class="n">get_depot_details</span><span class="p">(</span><span class="n">depot_name</span><span class="p">,</span> <span class="s2">&quot;rw&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">write_format</span><span class="p">:</span>
            <span class="n">depot_details</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">write_format</span>
        <span class="n">conf_obj</span> <span class="o">=</span> <span class="n">WriteConfig</span><span class="p">(</span><span class="n">depot_details</span><span class="o">=</span><span class="n">depot_details</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__create_output_instance</span><span class="p">(</span><span class="s2">&quot;Writer&quot;</span><span class="p">,</span> <span class="n">conf_obj</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__create_input_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">class_suffix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">conf_obj</span><span class="p">:</span> <span class="n">ReadConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Reader</span><span class="p">:</span>
        <span class="n">io_format</span> <span class="o">=</span> <span class="n">conf_obj</span><span class="o">.</span><span class="n">io_format</span><span class="o">.</span><span class="n">casefold</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input_format: </span><span class="si">{</span><span class="n">io_format</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;pulsar&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;FastBase</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;delta&quot;</span><span class="p">,</span> <span class="s2">&quot;deltabase&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Delta</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;postgresql&quot;</span><span class="p">,</span> <span class="s2">&quot;postgres&quot;</span><span class="p">,</span> <span class="s2">&quot;jdbc&quot;</span><span class="p">,</span> <span class="s2">&quot;mysql&quot;</span><span class="p">,</span> <span class="s2">&quot;oracle&quot;</span><span class="p">,</span> <span class="s2">&quot;redshift&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;JDBC</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;iceberg&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Iceberg</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;snowflake&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Snowflake</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;bigquery&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Bigquery</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;elasticsearch&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;ElasticSearch</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;File</span><span class="si">{</span><span class="n">INPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__create_output_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">class_suffix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">conf_obj</span><span class="p">:</span> <span class="n">WriteConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Writer</span><span class="p">:</span>
        <span class="n">io_format</span> <span class="o">=</span> <span class="n">conf_obj</span><span class="o">.</span><span class="n">io_format</span><span class="o">.</span><span class="n">casefold</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output_format: </span><span class="si">{</span><span class="n">io_format</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;pulsar&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;FastBase</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;delta&quot;</span><span class="p">,</span> <span class="s2">&quot;deltabase&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Delta</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">io_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;postgresql&quot;</span><span class="p">,</span> <span class="s2">&quot;postgres&quot;</span><span class="p">,</span> <span class="s2">&quot;jdbc&quot;</span><span class="p">,</span> <span class="s2">&quot;mysql&quot;</span><span class="p">,</span> <span class="s2">&quot;oracle&quot;</span><span class="p">,</span> <span class="s2">&quot;redshift&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;JDBC</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;iceberg&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Iceberg</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;snowflake&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Snowflake</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;bigquery&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;Bigquery</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">io_format</span> <span class="o">==</span> <span class="s2">&quot;elasticsearch&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;ElasticSearch</span><span class="si">{</span><span class="n">OUTPUT_STRING</span><span class="si">}{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="sa">f</span><span class="s2">&quot;FileOutput</span><span class="si">{</span><span class="n">class_suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">](</span><span class="n">conf_obj</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__is_local</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># elif urlparse(path).scheme in [&#39;&#39;, &#39;file&#39;]:</span>
        <span class="c1">#     return True</span>
        <span class="k">return</span> <span class="kc">False</span></div>


<div class="viewcode-block" id="refresh_global_data"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.refresh_global_data">[docs]</a><span class="k">def</span> <span class="nf">refresh_global_data</span><span class="p">(</span><span class="n">spark_session_builder</span><span class="p">:</span> <span class="n">SparkSessionBuilder</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">g_inputs</span><span class="p">,</span> <span class="n">g_outputs</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">g_dataos_token</span>
    <span class="n">g_inputs</span> <span class="o">=</span> <span class="n">spark_session_builder</span><span class="o">.</span><span class="n">parsed_inputs</span>
    <span class="n">g_outputs</span> <span class="o">=</span> <span class="n">spark_session_builder</span><span class="o">.</span><span class="n">parsed_outputs</span>
    <span class="n">g_dataos_token</span> <span class="o">=</span> <span class="n">spark_session_builder</span><span class="o">.</span><span class="n">api_token</span>

    <span class="n">spark</span> <span class="o">=</span> <span class="n">spark_session_builder</span><span class="o">.</span><span class="n">spark</span></div>
    <span class="c1"># pyflare_logger.update_spark_log_level(spark, spark_session_builder.log_level)</span>


<div class="viewcode-block" id="load"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.load">[docs]</a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">format</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">query</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read a dataset from the source.</span>

<span class="sd">    :param name: Depot address of the source.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param format: Read format.</span>
<span class="sd">    :type format: str</span>
<span class="sd">    :param driver: Driver needed to read from the source (optional).</span>
<span class="sd">    :type driver: str</span>
<span class="sd">    :param query: Query to execute (optional).</span>
<span class="sd">    :type query: str</span>
<span class="sd">    :param options: Additional Spark and source properties (optional).</span>
<span class="sd">    :type options: dict</span>

<span class="sd">    :return: A Spark DataFrame with governed data.</span>
<span class="sd">    :rtype: pyspark.sql.DataFrame</span>

<span class="sd">    :raises PyflareReadException: If the dataset does not exist or read access fails.</span>

<span class="sd">    **Examples**</span>

<span class="sd">    Iceberg:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        read_options = {</span>
<span class="sd">            &#39;compression&#39;: &#39;gzip&#39;,</span>
<span class="sd">            &#39;iceberg&#39;: {</span>
<span class="sd">                &#39;table_properties&#39;: {</span>
<span class="sd">                    &#39;read.split.target-size&#39;: 134217728,</span>
<span class="sd">                    &#39;read.split.metadata-target-size&#39;: 33554432</span>
<span class="sd">                }</span>
<span class="sd">            }</span>
<span class="sd">        }</span>

<span class="sd">        load(name=&quot;dataos://lakehouse:retail/city&quot;, format=&quot;iceberg&quot;, options=read_options)</span>

<span class="sd">    JDBC:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        read_options = {</span>
<span class="sd">            &#39;compression&#39;: &#39;gzip&#39;,</span>
<span class="sd">            &#39;partitionColumn&#39;: &#39;last_update&#39;,</span>
<span class="sd">            &#39;lowerBound&#39;: datetime.datetime(2008, 1, 1),</span>
<span class="sd">            &#39;upperBound&#39;: datetime.datetime(2009, 1, 1),</span>
<span class="sd">            &#39;numPartitions&#39;: 6</span>
<span class="sd">        }</span>

<span class="sd">        load(name=&quot;dataos://sanitypostgres:public/city&quot;, format=&quot;postgresql&quot;,</span>
<span class="sd">             driver=&quot;com.mysql.cj.jdbc.Driver&quot;, options=read_options)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">global</span> <span class="n">g_inputs</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">g_dataos_token</span>
        <span class="n">java_import</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="p">,</span> <span class="s2">&quot;io.dataos.spark.authz.util.DataGovernor&quot;</span><span class="p">)</span>
        <span class="n">java_import</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="p">,</span> <span class="s2">&quot;io.dataos.heimdall.client.HeimdallClient&quot;</span><span class="p">)</span>
        <span class="c1"># to-do parse depot name form  depot address</span>
        <span class="n">os_input</span> <span class="o">=</span> <span class="n">DataOSInput</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">parsed_inputs</span><span class="o">=</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span>
                               <span class="n">apikey</span><span class="o">=</span><span class="n">g_dataos_token</span><span class="p">,</span> <span class="n">source_format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
                               <span class="n">driver</span><span class="o">=</span><span class="n">driver</span><span class="p">,</span> <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
        <span class="n">source_df</span><span class="p">,</span> <span class="n">depot_name</span> <span class="o">=</span> <span class="n">os_input</span><span class="o">.</span><span class="n">process_inputs</span><span class="p">()</span>
        <span class="n">depot_details</span> <span class="o">=</span> <span class="n">os_input</span><span class="o">.</span><span class="n">parsed_inputs</span><span class="p">[</span><span class="n">depot_name</span><span class="p">][</span><span class="s1">&#39;reader_instance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">read_config</span><span class="o">.</span><span class="n">depot_details</span>
        <span class="n">dataset_address</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;depot&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collection&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
                                    <span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)])</span>
        <span class="n">heimdall_client</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">HeimdallClient</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span><span class="o">.</span><span class="n">url</span><span class="p">(</span><span class="n">get_env_variable</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">HEIMDALL_BASE_URL</span><span class="p">))</span><span class="o">.</span><span class="n">apikey</span><span class="p">(</span>
            <span class="n">g_dataos_token</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="n">data_govern_jvm</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">DataGovernor</span><span class="o">.</span><span class="n">getInstance</span><span class="p">(</span><span class="n">heimdall_client</span><span class="p">)</span>
        <span class="c1"># user = generic_utils.authorize_user(spark, heimdall_client, g_dataos_token)</span>
        <span class="n">governed_data</span> <span class="o">=</span> <span class="n">data_govern_jvm</span><span class="o">.</span><span class="n">govern</span><span class="p">(</span><span class="n">source_df</span><span class="o">.</span><span class="n">_jdf</span><span class="p">,</span> <span class="n">dataset_address</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">governed_df</span> <span class="o">=</span> <span class="n">source_df</span>
        <span class="k">if</span> <span class="n">governed_data</span><span class="o">.</span><span class="n">_1</span><span class="p">()</span><span class="o">.</span><span class="n">isDefined</span><span class="p">():</span>
            <span class="c1"># here we are extracting first element of tuple we got from govern() response and converting java datafrme to</span>
            <span class="c1"># python df</span>
            <span class="n">governed_df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">governed_data</span><span class="o">.</span><span class="n">_1</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">spark</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">governed_df</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">PyflareReadException</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Check if dataset </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> exists and you have read access. Msg: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="minerva_input"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.minerva_input">[docs]</a><span class="k">def</span> <span class="nf">minerva_input</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">cluster_name</span><span class="o">=</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="s2">&quot;io.trino.jdbc.TrinoDriver&quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">global</span> <span class="n">g_inputs</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">g_dataos_token</span>
        <span class="n">java_import</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="p">,</span> <span class="s2">&quot;io.dataos.spark.authz.util.DataGovernor&quot;</span><span class="p">)</span>
        <span class="n">java_import</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="p">,</span> <span class="s2">&quot;io.dataos.heimdall.client.HeimdallClient&quot;</span><span class="p">)</span>
        <span class="n">minerva_in</span> <span class="o">=</span> <span class="n">MinervaInput</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">parsed_inputs</span><span class="o">=</span><span class="n">g_inputs</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span> <span class="n">apikey</span><span class="o">=</span><span class="n">g_dataos_token</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="n">driver</span><span class="p">,</span>
                                  <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">cluster_name</span><span class="o">=</span><span class="n">cluster_name</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
        <span class="n">source_df</span><span class="p">,</span> <span class="n">depot_name</span> <span class="o">=</span> <span class="n">minerva_in</span><span class="o">.</span><span class="n">process_inputs</span><span class="p">()</span>
        <span class="n">depot_details</span> <span class="o">=</span> <span class="n">minerva_in</span><span class="o">.</span><span class="n">parsed_inputs</span><span class="p">[</span><span class="n">depot_name</span><span class="p">][</span><span class="s1">&#39;reader_instance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">read_config</span><span class="o">.</span><span class="n">depot_details</span>
        <span class="n">dataset_address</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;depot&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;collection&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
                                    <span class="n">depot_details</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)])</span>
        <span class="n">heimdall_client</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">HeimdallClient</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span><span class="o">.</span><span class="n">url</span><span class="p">(</span><span class="n">get_env_variable</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">HEIMDALL_BASE_URL</span><span class="p">))</span><span class="o">.</span><span class="n">apikey</span><span class="p">(</span>
            <span class="n">g_dataos_token</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="n">data_govern_jvm</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">_jvm</span><span class="o">.</span><span class="n">DataGovernor</span><span class="o">.</span><span class="n">getInstance</span><span class="p">(</span><span class="n">heimdall_client</span><span class="p">)</span>
        <span class="c1"># user = generic_utils.authorize_user(spark, heimdall_client, g_dataos_token)</span>
        <span class="n">governed_data</span> <span class="o">=</span> <span class="n">data_govern_jvm</span><span class="o">.</span><span class="n">govern</span><span class="p">(</span><span class="n">source_df</span><span class="o">.</span><span class="n">_jdf</span><span class="p">,</span> <span class="n">dataset_address</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">governed_df</span> <span class="o">=</span> <span class="n">source_df</span>
        <span class="k">if</span> <span class="n">governed_data</span><span class="o">.</span><span class="n">_1</span><span class="p">()</span><span class="o">.</span><span class="n">isDefined</span><span class="p">():</span>
            <span class="c1"># here we are extracting first element of tuple we got from govern() response and converting java datafrme to</span>
            <span class="c1"># python df</span>
            <span class="n">governed_df</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">governed_data</span><span class="o">.</span><span class="n">_1</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">spark</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">governed_df</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">PyflareReadException</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Check if dataset </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> exists and you have read access. Msg: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="save"><a class="viewcode-back" href="../../../../pyflare.sdk.core.html#pyflare.save">[docs]</a><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dataframe</span><span class="p">,</span> <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Write the transformed dataset to the output sink.</span>

<span class="sd">    :param name: Output key to write.</span>
<span class="sd">    :type name: str</span>
<span class="sd">    :param dataframe: The DataFrame to write.</span>
<span class="sd">    :type dataframe: pyspark.sql.DataFrame</span>
<span class="sd">    :param format: Output format (e.g., iceberg, parquet).</span>
<span class="sd">    :type format: str</span>
<span class="sd">    :param mode: Write mode (default is \&quot;append\&quot;).</span>
<span class="sd">    :type mode: str</span>
<span class="sd">    :param driver: Driver to use for the sink (optional).</span>
<span class="sd">    :type driver: str</span>
<span class="sd">    :param options: Additional write configuration (optional).</span>
<span class="sd">    :type options: dict</span>

<span class="sd">    :raises PyflareWriteException: If dataset does not exist or write access fails.</span>

<span class="sd">    **Example**</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        write_options = {</span>
<span class="sd">            &quot;compression&quot;: &quot;gzip&quot;,</span>
<span class="sd">            &quot;iceberg&quot;: {</span>
<span class="sd">                &quot;table_properties&quot;: {</span>
<span class="sd">                    &quot;write.format.default&quot;: &quot;parquet&quot;,</span>
<span class="sd">                    &quot;write.parquet.compression-codec&quot;: &quot;gzip&quot;,</span>
<span class="sd">                    &quot;write.metadata.previous-versions-max&quot;: 3,</span>
<span class="sd">                    &quot;parquet.page.write-checksum.enabled&quot;: &quot;false&quot;</span>
<span class="sd">                },</span>
<span class="sd">                &quot;partition&quot;: [</span>
<span class="sd">                    {&quot;type&quot;: &quot;months&quot;, &quot;column&quot;: &quot;ts_city&quot;},</span>
<span class="sd">                    {&quot;type&quot;: &quot;bucket&quot;, &quot;column&quot;: &quot;city_id&quot;, &quot;bucket_count&quot;: 8},</span>
<span class="sd">                    {&quot;type&quot;: &quot;identity&quot;, &quot;column&quot;: &quot;city_name&quot;}</span>
<span class="sd">                ]</span>
<span class="sd">            }</span>
<span class="sd">        }</span>

<span class="sd">        save(name=&quot;dataos://lakehouse:sdk/city&quot;, format=&quot;iceberg&quot;,</span>
<span class="sd">             mode=&quot;append&quot;, options=write_options)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">global</span> <span class="n">g_outputs</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">g_dataos_token</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">DataOSOutput</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">dataframe</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">parsed_outputs</span><span class="o">=</span><span class="n">g_outputs</span><span class="p">,</span> <span class="n">apikey</span><span class="o">=</span><span class="n">g_dataos_token</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span>
                     <span class="n">sink_format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="n">driver</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">PyflareWriteException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Check if dataset </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> exists and you have write access. Msg: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, TMDC.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>