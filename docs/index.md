---
hide:
  - navigation
#   - toc
---
# DataOS Philosophy

Adopting an Operating System for data is not just another tooling shift or migration activity. While it is almost as simple as the former and not as challenging as the latter, the context of such a shift is entirely different. Enabling an OS for data is essentially a pivot in your data philosophy. Everything from how you approach and ingest data to how you understand and operationalise it undergoes a major transformation.

One of these core mindset shifts is the evolution from traditional two-dimensional tables to [Data Products](https://datadeveloperplatform.org/what_is_data_developer_platform/#what-is-a-data-product). While the former is an isolated unit of data wandering across the data ecosystem without governance or razor-focused purpose, the latter (Data Products) is a technologically aesthetic amalgam of well-defined purpose and execution. Only an Operating System design enables such a blend at scale.

DataOS, as a [direct implementation of an OS design specifically built for data](https://datadeveloperplatform.org/), allows users to build a product experience around data and tie efforts and initiatives to the business value. Moreover, Data Product being an atomic building block of software-like data stacks, makes DataOS truly an essential future-proofing kit- a cushion of flexibility to bear the storm of the rapidly changing data landscape; from traditional and modern data stacks to fabric and mesh-y frameworks.



## Your Familiar Operating System

Operating systems have been at the heart of enabling masses to access and leverage countless benefits of digital applications without the need to be skilled in infrastructure and dirty plumbing. Even app developers who are into heavy engineering need not bootstrap the whole system from scratch to build their applications. Instead, they put together different unique capabilities available on the OS to spin up these applications and deploy at scale.

> It’s **fast**, **standardised**, and **targetedly valuable**.
> 

*Exhibit A*: Xcode on macOS. Imagine if developers were required to check in on the macOS infra and fix its hiccups - there wouldn’t be as many apps as Xcode has helped produce. The ones that would exist wouldn’t be as established with as many advanced, value-adding, and innovative features.

Sadly and a bit surprisingly, the data space is still in a phase where data engineers are required to heavily focus on infra maintenance. Their hands are always full with open tickets, most of them requesting a plumbing job. As it is, truly skilled experts in the data space are rare, and most of them are sucked into plumbing the data ecosystem instead of producing data applications that directly impact their team’s ROI.
## An Operating System for Data

<aside class="callout">
💡 DataOS is built with the same philosophy as an operating system.
</aside>
<br/>

DataOS is the data stack that confidently puts data first and resurrects teams from maintenance-first loops. Being data-first may seem the obvious choice, but prevalent practices in data do not reflect it. It is not uncommon to spend countless hours solving infrastructure drawbacks and maintaining data pipelines. But take a step back to our OS analogy, and it becomes evident that every organisation does not need its own operating system (infrastructure) to drive profitable applications. They can instead install an operating system for data and run with it. We would go out on a limb and say this is where the data industry is converging, and the ability to focus on applications at scale is already a must-have competitive edge.

As would be expected from an operating system for data, it abstracts all the nuances of low-level data management, which otherwise suck out most of the data developer’s active hours. It provides a set of tools and services to help data professionals manage and analyze data more effectively. As a direct implementation of the [data developer platform specification](http://datadeveloperplatform.org), DataOS includes tools for data integration, processing, storage, and analysis, as well as governance and monitoring features to ensure that data is managed, compliant and secure. 

In conjunction with DDP specs, DataOS is designed to provide data professionals with a set of building blocks that they can use to build data products, services, and data applications more quickly and efficiently. Data developers can quickly spawn new applications and rapidly deploy to multiple target environments with configuration templates and declarative workload specifications with consistent monitoring and testing for high uptime. By providing a unified and standardised platform for managing data, DataOS helps organizations make better use of their data assets and drive business value.

A declarative system (OS) drastically eliminates the scope of fragility with precision-driven configurations and surfaces frequently-required RCA lenses with recommendations on demand, optimising resources and ROI. Most importantly, it allows a direct and asynchronous interface between data developers and data, eliminating complex layers of the infrastructure through customisable abstractions. It is important not to confuse this with inflexibility - a data engineer can always open up the system to shift the gears very specifically.
### DataOS Citizens

DataOS enables self-service for a broad band of data personas, including **data engineers, business users, and domain teams**. This again a direct parallel of the OS analogy. While a gamer uses a Mac to run games, an accountant uses the same machine to process heavy Excel files. While a musician uses a phone to create complex media files, a grandparent uses it to video call the grandkids.

> Same platform. Different use cases.
> 
> 
> Same infrastructure. Variety of simple and complex solutions.
> 

In all cases, neither of the users needs to understand the low-level technology or build their applications from scratch to start using the applications for their desired outcomes. But does that mean there’s no one on the other end figuring out the infrastructure complexities of the laptops, PCs, and phones?

There indeed is a very small (compared to the size of the user base) team behind infrastructure development and maintenance, and their job is to ensure all the users on the other side have a seamless experience without the need to get into the nitty-gritty. If the infrastructure is well-kept, users are abstracted from the pains of booting, maintaining, and running the low-level nuances of day-to-day applications that directly bring them value. The only job of the data developer now is to build and enable data applications that directly power business value. And while the infrastructure takes care of the resources, environments, provisioning, and supervisory activities, a small dedicated platform team ensures that the infra is healthy and ready to do its job.

So is the case with a well-designed data developer platform. While smaller dedicated platform teams manage and regulate the infrastructure, larger teams of data developers are able to focus their time and effort on building data applications instead of worrying about plumbing issues. Applications across a broad range, including AI/ML, data sharing, and analytics, are all enabled at scale through the virtue of the same philosophy.
### Why an OS for Data is the next step in the larger scheme of things?

As more tools pop in the data ecosystem, they increasingly develop the need to become independently operable, often based on user feedback. This results in multiple data catalogs, governance engines, observability engines and more heavy duplicates- all localised to different tools and restricted with specific access and operating patterns. The prevalent systems are mostly assembled in nature - as a result of ad-hoc solutioning. Any assembled data stack cannot be thought of as a product but a bunch of disparate capabilities thrown together in a mix.

What follows from assembled systems is the sudden overwhelm of managing multiple limbs of the system, and therefore, increasing complexity and friction for end users to get their hands on the data. While business domains, such as marketing, sales, support, etc., have to jump multiple hops to achieve the data they need, the organisation feels the pressure to lift all dependencies clogging the central data team and distributing the workload across these domains. While the idea seems very appealing on theoretical grounds, how feasible is it in the field? If we lay this idea on any working business model, there are a few consequences:

- Not enough skilled professionals to allocate to each individual domain - Practically, how feasible is the idea of having data teams for each domain?
- Not enough professionals or budget to disrupt existing processes, detangle pipelines, and embed brand-new infrastructures.
- Not enough experts to help train and onboard during migration.

It’s both a skill- and resource-deficit issue. Moreover, with decades spent on evolving data stacks with not much value to show, organisations are not ideally inclined to pour in more investments and efforts to rip and replace their work. In essence, 𝐀𝐮𝐭𝐨𝐧𝐨𝐦𝐲 instead should become the higher priority over Decentralisation if that is the ultimate objective.

<aside>
💡 As we have established in the above sections, enabling autonomy for a host of personas is the number one objective of any operating system design. Teams can even use this autonomy and flexibility to create decentralised models with far less resources, but that is a secondary and one of many objectives that can be established through autonomy across several layers of data producers and engineers.
</aside>

### Bearing the Weight of Rapid Tech Evolution

DataOS is a cushion for trends. It was not long ago when data fabric was taking the world by storm, while today, most conversations are inlining toward the data mesh. Tomorrow, there might be a new data design architecture that CTOs and CFOs fancy. The harsh reality is no one data design architecture is non-disruptive or simple to implement. It takes dedicated time, effort, and investment.

Does this mean that every time a new holy grail is discovered, the entire stack needs to be ripped off and expended? Not if you have a DDP in place. Let’s say the DDP is the decryptor of all the complex scriptures in the holy grail. You place the cup in the socket, and the hall lights up.

DataOS developed after the core principles, provides a set of primitives that the architect can compose together in any arrangement to enable higher-order complex design patterns. The primitives in the DDP are uniquely identified as non-negotiable atomic units of any data stack. What’s more is, due to workload-centric development capabilities, this process becomes almost declarative, saving tons of resources, time, and money.
